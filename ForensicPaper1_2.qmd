---
title: "Planning a trial in orthopaedic sports medicine: Building on a critique of Pinczewski et al 2007"
author: "Corey Scholes"
affiliation: "EBM Analytics"
version: 1.0
date: "2025-Feb-15"
date-modified: "2025-Mar-18"
type: website
editor: visual
code-annotations: true
execute: 
  echo: true
  warning: false
  message: false
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
    
bibliography: ForensicPapers.bib
---

# Analysis Preamble

This analysis acts as a training activity to apply techniques described in [@heathers2025].

I will extend this approach, by encapsulating a review within the contemporary reporting guidelines for the trial reported in the paper in question.

The analysis was conducted in RStudio IDE (RStudio 2024.12.0+467 "Kousa Dogwood" Release) using *Rbase* [@base], *quarto* [@quarto] and attached packages.

## My Conflicts Up Front

-   I am a shareholder in [EBM Analytics](www.ebmanalytics.com.au).

    -   I declare an institutional engagement with Smith and Nephew (see below) for a small project \>3 years ago.

-   I would call myself an acquaintance of the study authors

    -   I have co-authored a paper with Justin Roe [@Oussedik2012].

-   Am I jealous of the citation record of this article - absolutely not, my interest here is for us to be able to move the conversation forward into the contemporary period and better serve future patients.

# Executive Summary

The article has not been retracted, not have any comments been made about it on [PubPeer](https://pubpeer.com/).

It is an attempted randomised (partial randomisation) comparison between two sources of graft material for ACL reconstruction that is potentially influenced by bias in patient selection, lack of blinding and multiplicity of analyses for outcomes that have not been pre-registered. The aims and objectives are not sufficiently specific or structured to allow adequate assessment of the analysis. It is likely that the study never existed in a state of clinical equipoise with respect to the treatment options, or the risk-benefits of each option were not fully understood at the time. Inclusion/exclusion criteria for several analyses have been altered between followup reports on the same cohort and many of the findings still being cited in the contemporary literature are not supported when considering the issues with the statistical analysis and the lack of sample size (power) calculation prior to patient recruitment. The key findings are vulnerable to competing risks (e.g. graft survival) and many cited findings rely on poorly reported regression analyses, where their interpretation has been subject to the Table 2 fallacy.

Overall, this article should probably be retired from public discourse as a premature trial, that lacked robust design and was haphazardly reported, which compared an emerging (at the time of recruitment) treatment option compared to the accepted standard for ACL rupture in patients presenting for surgical review. Patient preference for short-term function restoration balanced against potential of elevated risk of re-rupture remains an under-explored component of establishing clinical equipoise in this patient population.

## Preparation

Load up required packages in advance using *pacman* package (v`{r} utils::packageVersion("pacman")`) [@pacman]. Citations applied to each library at first use in the text.

```{r, Prepare Packages}

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  "cardx",
  "parallelly",
  "gargle",
  "googledrive",
  "gert",
  "rsprite2",
  "scrutiny",
  "pwrss",
  "parallel",
  "progressr",
  "stringdist",
  "simsurv",
  "powerSurvEpi",
  "wmwpow",
  "pwrss",
  "confintr",
  "simstudy",
  "statcheck",
  "gert",
  "rcrossref",
  "httr",
  "jsonlite",
  "synthesisr",
  "reshape",
  "future",
  "furrr",
  "memoise",
  "googlesheets4",
  "openxlsx2",
  "readr",
  "purrr",
  "tidyverse",
  "tidymodels",
  "tidytext",
  "stopwords",
  "tictoc",
  "lubridate",
  "forcats",
  "gt",
  "consort",
  "gtsummary",
  "flextable",
  "survival",
  "ggplot2",
  "ggdist",
  "ggsurvfit",
  "ggfortify",
  "mice",
  "marginaleffects",
  "patchwork",
  "naniar",
  "quantreg",
  "broom",
  "broom.helpers",
  "labelled",
  "epoxy",
  "broom.mixed",
  "lme4",
  "janitor",
  "progressr",
  "DT",
  install = TRUE,
  update = FALSE
)

```

## Authorisations

Pre-authorise access to registry datasets using the *gargle* package (v`{r} utils::packageVersion("gargle")`) [@gargle].

```{r, Pre-authorisation, echo = FALSE}

# Set the cache location
options(gargle_oauth_cache = ".secrets")

# Use the saved token for non-interactive auth
drive_auth(email = "cscholes@ebma.com.au", 
          cache = ".secrets")
```

```{r, Authorisation Options, echo = FALSE}

options(
  gargle_oauth_cache = ".secrets",
  gargle_oauth_email = TRUE
)

drive_auth(cache = ".secrets", email = TRUE)
```

Cloned the RW git repo to the environment to bounce off later.

```{r, Retrieve RW Database}

# Set the repository URL and create a temporary directory
repo_url <- "https://gitlab.com/crossref/retraction-watch-data"
temp_dir <- tempdir()
repo_path <- file.path(temp_dir, "retraction-watch-data")

# Clone the repository to the temporary directory
git_clone(
  url = repo_url, 
  path = repo_path,
  verbose = FALSE
  )

# Access files from the repository
data_file_path <- file.path(repo_path, "retraction_watch.csv")
Retractions <- read.csv(data_file_path)
```

## Reporting Framework

To provide some structure to scrutinising this article - the following guidelines were utilised.

CONSORT 2010 - [@moher2010]

CONSORT Abstracts - [@hopewell2008]

CONSORT Parallel group trials - [@moher2010; @consort2010]

CONSORT Nonpharmacologic treatments - [@boutron2017]

CONSORT PRO - [@calvert2013]

CONSORT Harms - [@junqueira2023]

CONSORT Outcomes Extension 2022 - [@butcher2022]

# Selected Citation

[@pinczewski2007]

```{r, TargetDOI}

targetDOI = "10.1177/0363546506296042"

```

Retrieve the full citation using the *rcrossref* package (v`{r} utils::packageVersion("rcrossref")`) [@rcrossref].

```{epoxy, Full Citation}

{rcrossref::cr_cn(dois = targetDOI, format = "text", style = "apa")}

```

## Selection Rationale

The selected paper appears at number 2 in "The top 100 most cited articles in Australian orthopaedic surgery" [@mcmillan2024].

It has been cited 288 times (pubmed) or 524 times (crossref), depending on which citation database you trust the most.

[![Metrics of selected citation as of 15-Feb-2025](AJSM%20Metrics.png)](https://journals.sagepub.com/doi/10.1177/0363546506296042)

## Summary

You can review the abstract for this paper [here](https://journals.sagepub.com/doi/10.1177/0363546506296042). In brief, this was an attempted RCT comparing two sources of graft material for reconstructing the anterior cruciate ligament in patients participating in high levels of competitive sport at the time of injury. The selected citation is the 10-year follow up of the comparison between groups, with previous reports at 2, 5 and 7 year follow ups (see Trial Protocol).

# Bibliometric Analysis

The burning question was how this paper is being cited in the contemporary literature, what is the sentiment of this paper? Sentiment analysis of citations [@kilicoglu2019], is a very new concept for me - but I wanted to understand how the paper has been used in citations over the last couple of years.

I retrieved the citation list for this paper from *citationchaser* (the shiny app, I cant be bothered signing up for a plan for the API access) [@haddaway2022], which conducts a search through [lens.org](lens.org). Then draw in the bibliographic file with the *synthesisr* package (v`{r} utils::packageVersion("synthesisr")`) [@synthesisr].

```{r, Retrieve Citations, warning = FALSE, echo = FALSE}

# Define a temporary file location
temp_file <- tempfile(fileext = ".bib")  # Assuming your citations are in BIB format
                                        # Change extension if you have RIS, etc.

# Find your specific file 
citation_file <- googledrive::drive_find(
  pattern = "Paper1Citations",  # Adjust the search pattern
  n_max = 20
  
  ) 

# If you found your file, download it
if(nrow(citation_file) > 0) {
  googledrive::drive_download(
    file = citation_file[1,],  # Use the first match if multiple found
    path = temp_file,
    overwrite = TRUE
  )
} else {
  print("File not found. Check name or permissions.")
}

```

```{r, Read in Citations}

# Read the citations using synthesisr from the temporary file
Citations <- synthesisr::read_refs(
  filename = temp_file,
  tag_naming = "wos",
  return_df = TRUE,

  verbose = FALSE
)

# Optional: Remove the temporary file when done
file.remove(temp_file)



```

Then pull out the last couple of years of citations using *tidyverse* (v`{r} utils::packageVersion("tidyverse")`) [@tidyverse].

```{r, Filter Citations}
CitationRecent <- Citations |> dplyr::select(   year,   DO ) |> dplyr::filter(   year > 2022 )
```

I took the DOIs and passed them to my reference management software [PaperPile](https://paperpile.com/about/) (PaperPile LLC, USA) and imported them to a folder. The software was able to update the metadata and retrieve fulltext files for those that were open access.

I used the decision framework described by [@kilicoglu2019] to manually label them neutral, positive or negative sentiments with respect to the paper of interest. You can see the results (albeit selective unfortunately) in the table [here](https://docs.google.com/spreadsheets/d/1IYHUTOrSUvxQHVJ94ndt9BwrnIvejDg0EN1xY25k9js/edit?usp=sharing).

The main takeaway is that the majority are *neutral* and mostly use the paper of interest as a support in the introduction. This might indicate a certain level of self-correction in the literature as the trial steadily loses its relevance to the main topic it attempted to address. Either way, a more detailed analysis with changes in citation patterns over time, and without my selection bias, would be required to understand this fully.

## The paper

Check if it appears in the RW database using *stringr* (v`{r} utils::packageVersion("stringr")`) [@stringr]

```{r, Check Retractions Paper}

TargetCitation <- rcrossref::cr_works(dois = "10.1177/0363546506296042")

RWPaper <- Retractions |> dplyr::filter(
  stringr::str_detect(OriginalPaperDOI,TargetCitation$data$doi) 
)

```

Combine an if loop with the *epoxy* package (v`{r} utils::packageVersion("epoxy")`) [@epoxy] to assess whether there are any retractions.

```{r, Count Retractions}

if_else(
  nrow(RWPaper) < 1,
  "No Retraction Found",
  epoxy::epoxy("There were {nrow(RWPaper)} retractions identified")
)
```

There were 0 comments for this paper on PubPeer \[ 15-Feb-2025\].

## The authors

So I wrote a function to work through the surnames and bounce them against the RW database. We can argue about validation of this step until the cows come home, but for now I'm fairly satisfied that the individual authors do not have any retractions. The function is built on the following packages;

-   *stringr* (v`{r} utils::packageVersion("stringr")`) [@stringr]

-   *stringdist* (v`{r} utils::packageVersion("stringdist")`) [@stringdist]

-   *memoise* (v`{r} utils::packageVersion("memoise")`) [@memoise]

-   *parallel* (v`{r} utils::packageVersion("parallel")`) [@parallel]

-   *furrr* (v`{r} utils::packageVersion("furrr")`) [@furrr]

-   *progressr* (v`{r} utils::packageVersion("progressr")`) [@progressr]

You can see for yourself in the matches table below (maybe I missed one?).

```{r, Retractions Author - Function}


setup_parallel <- function(cores = NULL) {
  # Check for cloud environments or system limitations
  max_allowed_cores <- parallelly::availableCores()
  
  if (is.null(cores)) {
    # Use 1 less than available, but respect system limits
    cores <- min(parallel::detectCores() - 1, max_allowed_cores)
    # Ensure at least 1 core is used
    cores <- max(cores, 1)
  } else {
    # Make sure user-specified cores don't exceed limits
    cores <- min(cores, max_allowed_cores)
  }
  
  # Set up the future plan
  future::plan(future::multisession, workers = cores)
}

# Create memoized helper functions with explicit namespace references
mem_stringdist <- memoise::memoise(stringdist::stringdist)
mem_str_detect <- memoise::memoise(stringr::str_detect)

search_retractions_by_authors <- function(author_names, 
                                        retraction_data, 
                                        fuzzy_threshold = 0.2,
                                        date_from = NULL,
                                        date_to = NULL,
                                        cores = NULL) {

  # Initialize parallel processing
  setup_parallel(cores)
  
  # Don't nest with_progress calls - move this outside if calling from another function
  # that already uses with_progress
  p <- progressr::progressor(steps = 4)
  p(amount = 1, message = "Initializing...")
  
  # Convert author names to lowercase for case-insensitive matching
  author_names_lower <- tolower(author_names)
  
  # Process retraction data
  matching_retractions <- retraction_data %>%
    # Convert dates to proper format - handle potential NA values
    mutate(
      RetractionDate = as.Date(RetractionDate, format = "%m/%d/%Y"),
      OriginalPaperDate = as.Date(OriginalPaperDate, format = "%m/%d/%Y")
    ) 
  
  # Apply date filters if provided (with error handling)
  if (!is.null(date_from)) {
    date_from_parsed <- try(as.Date(date_from), silent = TRUE)
    if (!inherits(date_from_parsed, "try-error") && !is.na(date_from_parsed)) {
      matching_retractions <- matching_retractions %>% 
        filter(!is.na(RetractionDate) & RetractionDate >= date_from_parsed)
    }
  }
  
  if (!is.null(date_to)) {
    date_to_parsed <- try(as.Date(date_to), silent = TRUE)
    if (!inherits(date_to_parsed, "try-error") && !is.na(date_to_parsed)) {
      matching_retractions <- matching_retractions %>% 
        filter(!is.na(RetractionDate) & RetractionDate <= date_to_parsed)
    }
  }
  
  # Convert Author column to lowercase for matching
  matching_retractions <- matching_retractions %>%
    mutate(authors_lower = tolower(Author))
  
  p(amount = 1, message = "Processing data...")
  
  # Use safer versions of the string operations with error handling
  matching_retractions <- matching_retractions %>%
    mutate(
      exact_matches = furrr::future_map_chr(
        authors_lower,
        function(author_string) {
          if (is.na(author_string)) return("")
          
          matches <- author_names_lower[sapply(author_names_lower, function(name) {
            stringr::str_detect(author_string, stringr::str_c("\\b", name, "\\b"))
          })]
          stringr::str_c(matches, collapse = "; ")
        },
        .options = furrr::furrr_options(seed = TRUE)
      )
    )
  
  p(amount = 1, message = "Performing exact matching...")
  
  # Perform fuzzy matching with error handling
  matching_retractions <- matching_retractions %>%
    mutate(
      fuzzy_matches = furrr::future_map_chr(
        authors_lower,
        function(author_string) {
          if (is.na(author_string)) return("")
          
          individual_authors <- stringr::str_split(author_string, ";")[[1]] %>%
            stringr::str_trim()
          
          matches <- author_names_lower[sapply(author_names_lower, function(search_name) {
            min_dist <- min(sapply(individual_authors, function(x) 
              stringdist::stringdist(x, search_name, method = "jw")), na.rm = TRUE)
            !is.na(min_dist) && min_dist <= fuzzy_threshold
          })]
          
          stringr::str_c(unique(matches), collapse = "; ")
        },
        .options = furrr::furrr_options(seed = TRUE)
      )
    )
  
  p(amount = 1, message = "Performing fuzzy matching...")
  
  # Filter and select columns
  results <- matching_retractions %>%
    filter(exact_matches != "" | fuzzy_matches != "") %>%
    select(
      Title,
      Author,
      exact_matches,
      fuzzy_matches,
      Journal,
      Publisher,
      Country,
      RetractionDate,
      OriginalPaperDate,
      RetractionDOI,
      OriginalPaperDOI,
      Reason,
      everything(),
      -authors_lower
    )
  
  # Generate summary statistics with error handling
  summary_stats <- list(
    total_matches = nrow(results),
    matches_by_year = results %>%
      mutate(year = format(RetractionDate, "%Y")) %>%
      count(year, name = "retractions") %>%
      arrange(desc(year)),
    matches_by_publisher = results %>%
      count(Publisher, sort = TRUE, name = "retractions"),
    matches_by_country = results %>%
      count(Country, sort = TRUE, name = "retractions"),
    exact_vs_fuzzy = c(
      exact = sum(results$exact_matches != "", na.rm = TRUE),
      fuzzy_only = sum(results$exact_matches == "" & results$fuzzy_matches != "", na.rm = TRUE)
    ),
    date_range = if(nrow(results) > 0) {
      c(
        min = min(results$RetractionDate, na.rm = TRUE),
        max = max(results$RetractionDate, na.rm = TRUE)
      )
    } else {
      c(min = NA, max = NA)
    }
  )
  
  # Return results
  list(
    matches = results,
    summary = summary_stats
  )
}

# Clear memoization cache function
clear_retraction_search_cache <- function() {
  memoise::forget(mem_stringdist)
  memoise::forget(mem_str_detect)
  gc()  # Run garbage collection
}

```

Then pull out the search terms using *tidyverse.*

```{r, Retractions Author Surname}
# Set up handlers for progress reporting

handlers(handler_progress(
  format = ":spin :current/:total (:message) [:bar] :percent in :elapsed ETA: :eta",
  width = 100
))

# Extract just family names
author_surnames <- TargetCitation$data$author[[1]] |>
  pull(family)

# Run the search with more error handling
search_results <- tryCatch({
  # Don't nest with_progress here since it's already used in the function
  search_retractions_by_authors(
    author_surnames,
    Retractions,
    fuzzy_threshold = 0.2, 
    date_from = "2020-01-01",
    date_to = "2024-12-31",
    cores = 2  # Limit cores explicitly for Connect environment
  )
}, error = function(e) {
  # Print the error
  message("Error in search: ", e$message)
  # Return empty results as fallback
  list(
    matches = tibble(),
    summary = list(
      total_matches = 0,
      matches_by_year = tibble(year = character(0), retractions = integer(0)),
      matches_by_publisher = tibble(Publisher = character(0), retractions = integer(0)),
      matches_by_country = tibble(Country = character(0), retractions = integer(0)),
      exact_vs_fuzzy = c(exact = 0, fuzzy_only = 0),
      date_range = c(min = NA, max = NA)
    )
  )
})

# Access the results
AuthorMatches <- search_results$matches
summary_stats <- search_results$summary

```

Then present in a table using *gt* package (v`{r} utils::packageVersion("gt")`) [@gt].

```{r, Author Matches}


gt::gt(AuthorMatches |> dplyr::select(
  Title,
  Author,
  Journal,
  Country,
  exact_matches,
  fuzzy_matches,
  RetractionDate
)) |>
  tab_options(
    table.width = px(1200),  # Wider overall table
    table.font.size = px(12)  # Slightly smaller font
  ) |>
  cols_width(
    Title ~ px(200),          # Wider for full titles
    Author ~ px(200),         # Space for multiple authors
    Journal ~ px(200),        # Space for journal names
    Country ~ px(150),        # Space for multiple countries
    exact_matches ~ px(75),     # Wide space for institutions
    fuzzy_matches ~ px(75),     # Wide space for institutions
    RetractionDate ~ px(75)     # Wide space for institutions
  ) |>
  fmt_markdown(columns = everything()) |>
  text_transform(
    locations = cells_body(),
    fn = function(x) {
      vapply(x, function(x) {
        if (is.character(x)) {
          # Insert line breaks in long strings
          gsub("([,;]) ", "\\1\n", x)
        } else {
          as.character(x)
        }
      }, character(1))
    }
  ) |>
  tab_style(
    style = cell_text(whitespace = "pre-wrap"),  # Preserve line breaks
    locations = cells_body()
  ) |>
  cols_align(
    align = "left",
    columns = everything()
  ) |>
  knitr::knit_print()

```

# Trial Information

So first things first, this study is not a randomised trial. In the methods, it's described as a "prospective controlled trial". More on that later.

## CONSORT \[23\] Registration

No prior trial registration in [clinicaltrials.gov](clinicaltrials.gov). Manual search performed 17-Feb-2025.

## CONSORT \[24\] Trial Protocol

<!--# Where the full trial protocol and other relevant documents can be accessed, including additional data on harms -->

This gets a little trickier. The protocol is not described fully in this paper, but is somewhat described throughout the multiple previous papers from the same trial. As far as I can tell though, there was no protocol published prior to the first follow up paper.

Study with follow up at 7 years - [@roe2005]

Study with follow up at 5 years - [@pinczewski2002]

Study with follow up at 2 years - [@corry1999]

## CONSORT \[25\] Funding

Funding provided by

-   The Australian Institute of Musculoskeletal Research

    -   A local not-for-profit entity to support research within a group of surgeons in which the senior author was a key influencer

-   Smith and Nephew Endoscopy

    -   Manufacturer of the fixation and surgical instrumentation for the ACL reconstruction procedures

    -   Fund fellowships for less experienced surgeons to train under the senior author

# Title and Abstract

## CONSORT \[1a\] Trial Identification

The title identifies the study as a "prospective controlled trial".

## CONSORT \[1b\] Structured summary

<!--# Structured summary of trial design, methods, results, and conclusions -->

<!--# P1b: The PRO should be identified in the abstract as a primary or secondary outcome -->

The PROs used in the study are *not* identified in the abstract as primary or secondary outcomes in the trial.

+--------------------------------+-------------------+------------------------------------------------+
| Item                           | Present \| Absent | Comments                                       |
+================================+===================+================================================+
| Title (identify as randomised) | Not applicable    |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Trial design                   | Absent            |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Methods                        | Present           | Eligibility criteria for participants          |
|                                |                   |                                                |
| -   Participants               | Present           | Primary outcome not defined                    |
|                                |                   |                                                |
| -   Interventions              | Present           |                                                |
|                                |                   |                                                |
| -   Outcome                    | Not applicable    |                                                |
|                                |                   |                                                |
| -   Randomisation              | Absent            |                                                |
|                                |                   |                                                |
| -   Blinding                   |                   |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Results                        | Not applicable    | T                                              |
|                                |                   |                                                |
| -   Numbers randomised         | Absent            | The denominator in graft failure is inaccurate |
|                                |                   |                                                |
| -   Recruitment                | Absent            |                                                |
|                                |                   |                                                |
| -   Numbers analysed           | Present           |                                                |
|                                |                   |                                                |
| -   Outcome                    | Present           |                                                |
|                                |                   |                                                |
| -   Harms                      |                   |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Conclusions                    | Present           |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Trial registration             | Absent            |                                                |
+--------------------------------+-------------------+------------------------------------------------+
| Funding                        | Absent            |                                                |
+--------------------------------+-------------------+------------------------------------------------+

: Summary of CONSORT Abstract Guidelines

# Introduction

## CONSORT \[2a\] Scientific Background and Explanation

<!--# Including background and rationale for PRO assessment -->

An important element of a clinical trial in this domain is to establish the *clinical equipoise* of the interventions and I dont think this was established here at all. In the present day, we have frameworks such as IDEAL [@McCulloch2009] that were developed specifically for the introduction of new surgical techniques and devices, that provide a graduated approach to preparing and supporting the concept of equipoise between the new and incumbent surgical treatments. While the introduction lays out different graft options for ACL reconstruction, it could have done more to establish the equivalent expectations of outcomes after graft selection.

Importantly there is no background or rationale stated for assessment of patient-reported outcomes.

## CONSORT \[2b\] Specific Objectives or Hypotheses

<!--# Specific objectives or hypotheses for outcomes of benefits and harms -->

<!--# P2b: The PRO hypothesis should be stated and relevant domains identified, if applicable -->

The paper aim as stated;

> *This study represents a report on the long-term outcomes of ACL reconstruction on knee function using an endoscopic technique, as well as a prospective comparison of the isolated effects of one extrinsic variable (graft choice).*

Herein lies many of the problems I have with this paper. It doesnt follow a *pico(s)* structure first introduced by [@thewell1995], with the *s* a more recent introduction \[citation\] representing the study design. Without a focused question following this structure, it becomes difficult to assess whether the trial is appropriately reported or adequately structured to address its primary aim. In addition, there are no specific objectives or hypotheses related to outcomes of benefits or harms (as per CONSORT Harms) and no mention of patient-reported outcomes (as per CONSORT PRO extension).

# Methods - External assessment

This paper should have been put through the wringer by SR-MA of graft type in ACL reconstruction. Let's do a quick summary of what others have said about the methods through RoB or methodology assessments in previous reviews.

Filter down the citation list for recent systematic reviews.

```{r}

CitationsSR <- Citations |> dplyr::filter(
  stringr::str_detect(title,"(systematic.*review)|(meta.*analysis)")
) |> dplyr::arrange(
  year
)

```

## Risk of Bias

A recent review [@sollberger2022] attempted to assess long term results after ACLR with PT vs HS autograft with a min follow up of 10 years, but did not include this paper in their analysis. Another review [@migliorini2020] included it in their quality assessment, but did not break down their RoB ratings by individual paper.

One systematic review [@janssen2017] used the Cochrane library checklist for RCTs, with two reviewers conducting independent ratings. It's important to keep in mind that this checklist is not currently the recommended method for assessing risk of bias in RCTs (chapter 8) [@Cumpston2019], but it does give us some idea of the methodological issues with this citation of interest, before we start our own review. The authors classified this trial as a *clinical controlled trial* (no formal randomisation). The overall rating from the combined checklist score was *Questionable (*score was between 30% and 50%). The citation of interest was marked down for the following items;

-   Lack of randomisation

-   Lack of blinding (patient, therapist, outcome assessor)

-   Lack of intention-to-treat analysis

While it was marked OK for an *acceptable lost-to-followup*, I think this is debatable and I will cover this in more detail later on.

# Methods - Trial Design

## CONSORT \[3a\] Description of trial design

<!--# Include allocation ratio -->

Prospective controlled trial.

This term is usually reserved for randomised trials, which this is not in reality. This is really an interrupted cohort study, or an interrupted time series.

<!--# Come back to this later -->

## CONSORT \[3b\] Changes to methods

<!--# after trial commencement; Come back and check this -->

Changes to eligibility may have altered or been reinterpreted at some point after trial commencement.

# Methods - Participants

## CONSORT \[4a\] Eligibility criteria

<!--# Not PRO-specific, unless the PROs were used in eligibility or stratification criteria -->

Recreate eligibility for clarity

+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
| Category  | Inclusion                             | Exclusion                                                                                        | Comments |
+===========+=======================================+==================================================================================================+==========+
| Patient   | Desire return to competitive activity |                                                                                                  |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
| Pathology | Complete ACL rupture                  | Additional ligament injury such that reconstruction was deemed necessary                         |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           | Grade 2 Lachman (or above)            | Chondral damage                                                                                  |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           | Positive pivot shift                  |                                                                                                  |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
| Treatment |                                       | Meniscal damage such that meniscectomy of \>1/3 of one (medial or lateral) meniscus was required |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
| Other     | Failed nonoperative treatment         | Previous meniscectomy                                                                            |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           |                                       | Abnormal radiographic image                                                                      |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           |                                       | Abnormal contralateral knee                                                                      |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           |                                       | Patients seeking compensation for their injury                                                   |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+
|           |                                       | Patients who did not wish to participate in a research program                                   |          |
+-----------+---------------------------------------+--------------------------------------------------------------------------------------------------+----------+

<!--# The representativeness of the sample is questionable -->

Yes, the representativeness of the sample is questionable for a number of reasons. However, a trial of this type need not be representative, as the aims of a trial are to "Provide evidence for **relative** treatment effectiveness over an adequate time horizon for assessing target patient outcomes" ([Harrell, 2023](https://www.fharrell.com/post/rct-mimic/ "RCT generalisability")). Harrell goes on to note that knowledge of the relative effect from an RCT combined with the absolute risk of an outcome from observational data can be combined to assess individual treatment efficacy. Others have observed that treatment effects can remain the same even when trial participants differ from the target population [@bradburn2020], this needs to be replicated in our present context here though. Still others have argued against the ingrained notion in clinical science that representative patient samples are the only mechanism by which findings can be appropriately generalised [@rothman2013].

The authors *have* mentioned that the trial can be used to establish a baseline of outcomes in this population, and I think this an overreach given the limitations on its external validity.

<!--# When applicable, eligibility criteria for centers and for care providers -->

Single-centre and single-surgeon study, eligibility criteria for centres and care providers not required.

## CONSORT \[4b\] Settings and locations of data collection

<!--# why is this important - retrieve from guidance and elaboration. "Information...is crucial to judge the applicability and generalisability of the trial. Other aspects...may also affect a study's external validity. -->

# Methods - Interventions

The intervention is arthroscopic reconstruction of the anterior cruciate ligament using autograft (material retrieved from the patient) during the operation and it is described the most in [@pinczewski2002]. There are numerous elements to the surgery that can vary;

-   Graft retrieval (addressing the defect)

-   Graft preparation (steps to convert the tendon graft into a structure that broadly matches the dimensions of the original ligament)

-   Arthroscopy portal placement

-   Tunnel placement (tibia and femur; where the ends of the prepared graft will be fixed)

-   Graft fixation (technique and hardware)

-   Closure

An important element of surgical outcomes in this context is the short-term rehabilitation approach. In the context of 10-year followup, the influence of rehabilitation might be relatively indirect on outcomes, or certainly weakened compared to earlier follow ups.

## CONSORT \[5\] Interventions for each Group

The major differences in intervention, which has implications for the ability to blind group allocation, was the graft retrieval. One group had graft material retrieved from the front of the knee, and the other group from the back of the knee. Importantly, one technique required bone grafting (PT group), which impacted the recommendations for weightbearing and short-term activity restrictions. Ultimately, these differences contributed to the randomisation aspect of the trial being abandoned (see Methods - Randomisation).

# Methods - Outcomes

## CONSORT \[6a\] Primary and Secondary

<!--# Completely defined prespecified primary and secondary outcomes, for both benefits and harms, including how and when they were assessed -->

Primary and secondary outcomes were not specified in any of the trial reports. I have tabled up the outcomes for clarity and bolded the outcomes that could be considered as primary outcomes.

+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
| Category            | Outcome                                     | Type          | Comments                                                                   |
+=====================+=============================================+===============+============================================================================+
| Adverse Events      | **Ipsilateral graft intact**                | Binary;       |                                                                            |
|                     |                                             |               |                                                                            |
|                     |                                             | Time to event |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Contralateral ligament intact               | Binary;       |                                                                            |
|                     |                                             |               |                                                                            |
|                     |                                             | Time to event |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Ipsilateral adverse events (complications)  | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Ipsilateral further surgery                 | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Harvest site symptoms                       | Ordinal       |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
| Subjective symptoms | **Symptoms with strenuous activity (IKDC)** | Ordinal       | [@hefti1993]                                                               |
|                     |                                             |               |                                                                            |
|                     |                                             |               | Person completing with patient - practice physiotherapist                  |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Lysholm Knee Score                          | Continuous    | [@tegner1985]                                                              |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Sports participation                        | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Knee-related reduction in activity          | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Kneeling pain                               | Continuous    |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
| Objective testing   | **Lachman Grade**                           | Ordinal       |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Pivot Shift                                 | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
|                     | Instrumented Laxity                         | Binary        |                                                                            |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
| Radiographic        | X-ray grading                               | Ordinal       | IKDC guidelines for radiographic assessment [@hefti1993]                   |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+
| Composite Endpoint  | *Ideal* Ouctome                             | Binary        | Combination of IKDC Grade A and no evidence of radiographic osteoarthritis |
+---------------------+---------------------------------------------+---------------+----------------------------------------------------------------------------+

<!--# Evidence of PRO instrument validity and reliability should be provided or cited if available including the person completing the PRO and methods of data collection (paper, telephone, electronic, other) -->

The inclusion of paediatric patients in the sample (see CONSORT 15) raises issues of validity with respect to the PROMs utilised. Granted the IKDC version used is the original and not the IKDC2000 used more broadly after the turn of the century. The IKDC2000, in which the subjective knee score component is based largely on the same questions as the version used in this study, is not validated for paediatric patients. In their defence, the paediatric version of the IKDC2000 would not be published for another decade [@nasreddine2016] after publication and some quarter century after the surgeries. However, It is also contended that the Lysholm is not validated for paediatric populations either [@fabricant2020]. The IKDC was collected in person and facilitated by a physiotherapist during an in-clinic visit. It is not stated, but I presume the "self-administered" Lysholm scale was completed during the same visit. Interestingly, there is no mention of following up patients by phone for PROMs.

## CONSORT \[6b\] Changes after commencement

Outcome switching from trial plan - commencement to analysis and reporting is problematic in trials [@altman2017]. This is one of the key weaknesses of this work - the outcomes have been potentially switched from one paper to the next based on interest over time. With no firm primary outcome stated early on in the reporting process or pre-specified, it is entirely possible that reported outcomes have been prioritised based on i) altered levels of interest over time or ii) levels of significance at the time of comparison.

## CONSORT \[6c\] Non-prespecified harms

<!--# Describe if and how non-prespecified outcomes of benefits and harms were identified, including any selection criteria, if applicable -->

This is an area of weakness of reporting in this series of papers and particularly with the selected citation. There is limited structure to the detection, measurement or interpretation of harms reported. There is no description of how harms (complications) were defined in general, or with specific reference to any one harm category. With the benefit of hindsight, the it is clear that the incidence and progression of complications after ACL reconstruction is more complex than reported in this paper. More recent assessments of complications after ACLR [@rousseau2019] suggest that a more structured approach to assessment, particularly over such a long follow up is required. Importantly, the harms associated with the reconstruction procedure also have a confounding effect on ipsilateral and contralateral rerupture risk, more on that later.

# Methods - Sample size

This is the biggest mystery of this paper I think. The methods description is very clear about what the sample size is, but really nothing about how it was determined. The only mention of power is in the discussion of [@pinczewski2002] to say that the study is underpowered for detecting a difference in graft rupture incidence.

I will run some simulations below to prove the point, but I just dont think this study was adequately powered for any of the comparisons it has made between the groups.

## CONSORT \[7a\] Determination

<!--# Not required for PRO unless it is a primary study outcome -->

Determination of the required sample size has not been described in this paper or any others in the series. I will focus this report on a quick assessment of the estimated power for a couple of comparisons.

I'm going to start with the *IDEAL* *outcome* (see CONSORT 6a) and assess the achieved power. I created the datatable of groupings directly using the numbers described in Table 5 of the paper. This *should* be the floor sample sizes available, given the availability of assessment data for both groups. Ran a quick check to make sure the numbers came across ok.

But then when I tried to recreate the outcome vector, I was convinced I was going mad - as I couldnt get the proportions to replicate what was in the paper. I spent ages fiddling around with rounding the proportions to no avail, so here is the original reporting with code below.

```{r}

dt1 <- genData(1110)

dt1$Graft <- c(rep(0, 580), rep(1, 530))

set.seed(2065)
# Define the conditions
defC <- defCondition(
  condition = "Graft == 0",
  formula = 0.689655,
  dist = "binary",
  link = "identity"
                    )
defC <- defCondition(
  defC, 
  condition = "Graft == 1",
  formula = 0.471698,
  dist = "binary",
  link = "identity"
                    )

# Generate the outcome based on conditions
dt2 <- addCondition(defC, dt1, newvar = "outcome")

# Verify the rates
dt2[, mean(outcome), by = Graft] |> gt::gt() |> fmt_number(columns = V1, decimals = 3)

```

```{epoxy}

Eventually, I had to resort to a manual back-calculation combined with rounding to estimate the positive cases in the HT group (n = {round(0.69*58,0)}) and the PT group (n = {round(0.47*53, 0)}).

```

Plugging those numbers in, the dataframe could be replicated.

```{r}

set.seed(2065)

# Create base data frame
IdealSim <- data.frame(id = 1:111)

# First assign the Graft variable
IdealSim$Graft <- c(rep(0, 58), rep(1, 53))

# Then assign outcomes separately for each group
IdealSim$Outcome <- NA  # Initialize with NA
IdealSim$Outcome[IdealSim$Graft == 0] <- c(rep(0, 18), rep(1, 40))
IdealSim$Outcome[IdealSim$Graft == 1] <- c(rep(0, 28), rep(1, 25))

# Verify
table(IdealSim$Graft, IdealSim$Outcome)

# Or simply
IdealSim %>%
  group_by(Graft) %>%
  summarize(Proportion = mean(Outcome)*100) |> gt::gt() |> fmt_number(columns = Proportion, decimals = 3)

```

Write a function to simulate the *same* between-group test.

```{r}

# Function to run 1000 Wilcoxon tests on simulated data
run_wilcoxon_simulation <- function(data, outcome_var, group_var, n_sims = 1000, alpha = 0.05) {
  # Input validation
  if (!is.data.frame(data)) {
    stop("Input must be a data frame")
  }
  
  if (!(outcome_var %in% names(data))) {
    stop(paste("Variable", outcome_var, "not found in data"))
  }
  
  if (!(group_var %in% names(data))) {
    stop(paste("Variable", group_var, "not found in data"))
  }
  
  # Create formula
  formula_str <- paste(outcome_var, "~", group_var)
  test_formula <- as.formula(formula_str)
  
  # Initialize results storage
  results <- data.frame(
    sim_id = 1:n_sims,
    w_stat = numeric(n_sims),
    p_value = numeric(n_sims),
    significant = logical(n_sims)
  )
  
  # Set seed for reproducibility
  set.seed(2065)
  
  # Get unique groups and sample sizes for bootstrap
  unique_groups <- unique(data[[group_var]])
  if (length(unique_groups) != 2) {
    warning("Group variable should have exactly 2 levels for Wilcoxon test")
  }
  
  group1_data <- data[data[[group_var]] == unique_groups[1], ]
  group2_data <- data[data[[group_var]] == unique_groups[2], ]
  
  n1 <- nrow(group1_data)
  n2 <- nrow(group2_data)
  
  # Run simulations
  for (i in 1:n_sims) {
    # Create bootstrap samples by sampling with replacement
    bootstrap_sample1 <- group1_data[sample(1:n1, n1, replace = TRUE), ]
    bootstrap_sample2 <- group2_data[sample(1:n2, n2, replace = TRUE), ]
    
    # Combine the samples
    bootstrap_data <- rbind(bootstrap_sample1, bootstrap_sample2)
    
    # Run the Wilcoxon test
    test_result <- wilcox.test(test_formula, data = bootstrap_data)
    
    # Store results
    results$w_stat[i] <- test_result$statistic
    results$p_value[i] <- test_result$p.value
    results$significant[i] <- test_result$p.value < alpha
  }
  
  # Add summary statistics
  attr(results, "summary") <- list(
    mean_w_stat = mean(results$w_stat),
    median_w_stat = median(results$w_stat),
    mean_p_value = mean(results$p_value),
    median_p_value = median(results$p_value),
    significant_proportion = mean(results$significant),
    power = sum(results$significant) / n_sims
  )
  
  return(results)
}




```

Run the simulations and plot the results.

```{r}
# 

# Run 1000 Wilcoxon tests
IdealTest <- run_wilcoxon_simulation(
  data = IdealSim,
  outcome_var = "Outcome",
  group_var = "Graft",
  n_sims = 1000
)

```

Table up the results;

```{r}

tbl_summary(
  IdealTest,
  include = !sim_id,
  digits = list(
    all_categorical() ~ 1
  ))

```

```{epoxy}

The proportion of tests with a p-value < 0.05 was {nrow(IdealTest |> filter(p_value < 0.05))/1000}. 

```

and here is the distribution of p-values

```{r}

# Plot histogram of p-values
hist(IdealTest$p_value, breaks = 20, main = "Distribution of p-values", xlab = "p-value")
```

Next, we'll turn our attention to the time to event analysis of graft rupture.

First - simulate a time to event dataset based on the reported findings.

```{epoxy}

The 10 year survival was 86% (95%CI 79 - 94) for the HT group and 92% (95%CI 86 - 98) for the PT group. This produces a hazard ratio of {round(92/86, 2)}. The PT group had (3, 1, 3) ipsilateral failures at up to 5 years, 5 to 7years and 7 to 10 year follow up periods. The HT group had (7, 2, 3) ipsilateral failures over the same intervals. 

```

I wrote a (fairly lengthy) function to simulate the dataset and re-plot the survival curves using *survival* (v`{r} utils::packageVersion("survival")`) [@survival] and *ggsurvfit* (v`{r} utils::packageVersion("ggsurvfit")`) [@ggsurvfit] packages.

```{r}

set.seed(2065)

# Function to generate survival times for a group based on specified failure patterns
generate_group_data <- function(n_subjects, failures_by_period, periods) {
  # Initialize all subjects as censored at 10 years
  data <- data.frame(
    time = rep(10, n_subjects),
    status = rep(0, n_subjects)
  )
  
  # Total failures to distribute
  n_failures <- sum(failures_by_period)
  
  # Randomly select subjects who will fail
  fail_indices <- sample(1:n_subjects, n_failures)
  
  # Current position in fail_indices
  current_pos <- 1
  
  # Distribute failures across time periods
  for(i in 1:length(failures_by_period)) {
    if(failures_by_period[i] > 0) {
      # Get indices for this period's failures
      period_indices <- fail_indices[current_pos:(current_pos + failures_by_period[i] - 1)]
      
      # Generate random times within this period
      period_start <- if(i == 1) 0 else periods[i-1]
      period_end <- periods[i]
      
      # Assign failure times
      data$time[period_indices] <- runif(failures_by_period[i], 
                                       min = period_start, 
                                       max = period_end)
      data$status[period_indices] <- 1
      
      # Update position
      current_pos <- current_pos + failures_by_period[i]
    }
  }
  
  return(data)
}

# Define study parameters
n_pt <- 90
n_ht <- 90
periods <- c(5, 7, 10)

# Generate PT group data (3, 1, 3 failures in the periods)
pt_data <- generate_group_data(n_pt, c(3, 1, 3), periods)
pt_data$group <- "PT"

# Generate HT group data (7, 2, 3 failures in the periods)
ht_data <- generate_group_data(n_ht, c(7, 2, 3), periods)
ht_data$group <- "HT"

# Combine datasets
dt <- rbind(pt_data, ht_data)
dt$group <- factor(dt$group)

# Create survival object
Graftfit <- survival::survfit(Surv(time, status) ~ group, data = dt)

# Create plotting data frame
surv_df <- data.frame(
  time = Graftfit$time,
  surv = Graftfit$surv,
  lower = Graftfit$lower,
  upper = Graftfit$upper,
  group = rep(names(Graftfit$strata), Graftfit$strata)
)

# Create plot
SurvPlot <- ggsurvfit::ggsurvfit(Graftfit) +
  geom_step(data = surv_df, aes(x = time, y = surv, color = group), linewidth = 1) +
  geom_ribbon(data = surv_df, 
             aes(x = time, ymin = lower, ymax = upper, fill = group), 
             alpha = 0.2) +
  labs(x = "Time (years)", 
       y = "Survival Probability", 
       title = "Recreated Survival Curves",
       color = "Group",
       fill = "Group") +
  theme_minimal() +
  scale_y_continuous(limits = c(0.75, 1)) +
  scale_color_manual(values = c("group=HT" = "#E41A1C", "group=PT" = "#377EB8"),
                    labels = c("HT", "PT")) +
  scale_fill_manual(values = c("group=HT" = "#E41A1C", "group=PT" = "#377EB8"),
                    labels = c("HT", "PT")) +
  add_risktable()

knitr::knit_print(SurvPlot)

```

Let's double check I've got the right survival figures at the 10 year mark using *gtsummary* (v`{r} utils::packageVersion("gtsummary")`)[@gtsummary].

```{r}

SurvSum <- gtsummary::tbl_survfit(
  Graftfit,
  times = c(5,7,10)
)

knitr::knit_print(SurvSum)

```

I'm going to calculate the achieved power with a cox regression

```{r}

SurvDT <- dt |> dplyr::mutate(
  group = if_else(group == "PT", "C","E")
  )

SurvPowerChk <- powerSurvEpi::powerCT(
  Surv(time, status) ~ group,
	SurvDT,
	90,
	90,
	1.07,
	alpha = 0.05)

```

```{r}

GraftCox <- survival::coxph(
  Surv(time, status) ~ group,
  SurvDT
)


Graftzph <- survival::cox.zph(fit = GraftCox, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)

plot(Graftzph)
```

```{r}
print(Graftzph)
```

## CONSORT \[7b\] Interim Analyses and Stopping

The series of papers making up reporting of this trial really needed a more comprehensive approach to stopping parameters and planning for interim analyses, at what turned out to be 5, 7 and 10 year follow ups.

Interim analyses for efficacy allow a trial to be stopped early [@ciolino2023]. With the benefit of hindsight, there are a number of issues with long-term follow up of ACL reconstruction that confound a comparison between graft types at such a long follow up period. Namely, the incidence and severity of osteoarthritis present in each group. Considering the quality of reconstruction is one (arguably minor) component of osteoarthritis after ACL rupture, the validity of the comparison could be questioned.

In defence of the authors, the natural history of post-ACL rupture OA was still a developing concept when this study was implemented. Nevertheless, the lack of planning of longer-term followup or interim analyses and how they are compensated in the comparisons needs to be addressed in more detail.

# Methods - Randomisation

This was an attempted RCT that failed due to recruitment refusal.\
\
"*On October 28, 1993, we began a prospective randomized study of consenting patients who met the required criteria. However, by April 10, 1994, although 52 patients had been randomized, no further patients agreed to participate in randomization. This was because the patients were noticing, through comments from the physical therapist, that the use of hamstring tendon graft led to a more rapid recovery from surgery.*" [@pinczewski2002]

I dont even know what to do with this.

Clinical equipoise (didnt exist it seems)

Patient selection - exclusivity (patients self-selected based on perioperative care and functional constraints imposed)

<!--# Why the results cannot be intrepreted the same way as an RCT -->

<!--# What could have been done to strengthen the comparisons  -->

## CONSORT \[8a - 10\]

-   Sequence Method

-   Sequence Type

-   Allocation Concealment

-   Implementation

Not reported in this trial.

<!--# Type of randomisation; details of any restriction (such as blocking and block size) -->

<!--# Mechanism used to implement the random allocation sequence (such as sequentially numbered containers),describing any steps taken to conceal the sequence until interventions were assigned -->

<!--# Who generated the random allocation sequence, who enrolled participants, and who assigned participants to interventions -->

## CONSORT \[11a\] Blinding (Who)

<!--# If done, who was blinded after assignment to interventions (for example, participants, care providers, those assessing outcomes of benefits and harms) and how -->

There is no mention of blinding in any of the articles related to this trial. Even if randomisation didn't occur, blinding of everyone involved in the trial (as much as practicable), but particularly those responsible for measurement and analysis is crucial to mitigate potential biases.

## CONSORT \[11b\] Intervention Similarity

Not applicable

# Methods - Statistical Methods

The analysis description in this paper, definitively comparing graft types in ACLR reconstruction, is a total of four sentences. I just don't think this would (or should) pass muster in the contemporary period.

The data structure clearly has dependency within patients over time points, but is likely under-sampled to cater for a fully specified model (mixed effects). See *Sample Size.*

Let's breakdown each sentence;

*The outcomes were compared between the two groups at 10 years using the Mann-Whitney U test for the continuous measurements (KT1000, range of motion, Lysholm score) and ordered categorical variables (such as IKDC categories).*

Well, this is a cracking start - theoretically an MW U test can be applied to ordinal categorical responses, but gee-whiz, there are better approaches to use, particularly in this context. First of all, how were ties between groups corrected for? I suspect they werent and that means for a study that was probably already on the limits of power for the implied comparisons, using this test in this way chips away at what little power remained. Also, many of the variables are binary responses, which this test really wouldnt be appropriate for.

Second, "at 10 years" is a bit misleading, as comparisons at the earlier time points are also made in this paper, as well as previous papers in this series.

*Wilcoxon signed rank test was used to assess changes* *over time.*

Combining t-tests like this for within and between-group comparisons is quite the sign that a more comprehensive model should be employed here.

*Linear regression analysis was used to assess relationship between selected dependent and independent variables.*

So close, yet so far - linear regression gets a guernsey, but not to do with anything related to the aims of the paper. Almost made it.

*Statistical significance was assessed at the 5% level.*

While this is good to know, there are lots of other details we need before we get to this.

## CONSORT \[12a\] Comparison Between Groups

<!--# P12a: Statistical approaches for dealing with missing data are explicitly stated -->

There are a metric tonne of comparisons between groups in this paper. Let's see if we can table up what we're looking at.

Data assumption was non-parametric. <!--# Come back to this -->

+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Category            | Outcome                                     | Type                  | Model - Test                              | Comments                             |
+=====================+=============================================+=======================+===========================================+======================================+
| Adverse Events      | **Ipsilateral graft intact**                | Time to event         | Nil (KM used to establish survival rates) | A risk table would have been helpful |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Contralateral ligament intact               | Binary; Time to event | Nil (KM used to establish survival rates) | A risk table would have been helpful |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Ipsilateral adverse events (complications)  | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Ipsilateral further surgery                 | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Harvest site symptoms                       | Ordinal               | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Subjective symptoms | **Symptoms with strenuous activity (IKDC)** | Ordinal               | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Lysholm Knee Score                          | Continuous            | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Sports participation                        | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Knee-related reduction in activity          | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Kneeling pain                               | Continuous            | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Objective testing   | **Lachman Grade**                           | Ordinal               | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Pivot Shift                                 | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Instrumented Laxity                         | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Range of motion - extension                 | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Single-leg hop test                         | Binary                | Nil                                       |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Operative Findings  | Meniscal Injury                             | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
|                     | Meniscal Treatment                          | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Radiographic        | IKDC grading x-ray                          | Ordinal               | Between-Group: Mann-Whitney U Test        |                                      |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+
| Composite           | IDEAL outcome                               | Binary                | Between-Group: Mann-Whitney U Test        | Suspect not a valid test             |
+---------------------+---------------------------------------------+-----------------------+-------------------------------------------+--------------------------------------+

## CONSORT \[12b\] Additional Analyses

<!--# Methods for additional analyses, such as subgroup analyses and adjusted analyses -->

There are regression analyses reported under each of the main outcomes in the results. It is only described as "linear regression", with no other indication of the model construction (distribution, assumptions), variable selection or effect size uncertainty as well as the statistics package used.

While guidelines for reporting statistical analyses have been published subsequent to this analysis [@lang2014], with specific reference to linear regression, there is insufficient information provided to come close to replicating the findings reported.

# Results

Let's roll through the results by section and make some notes.

## CONSORT \[13a\] Participant Flow

<!--# For each group, the numbers of participants who were randomly assigned, received intended treatment, and were analysed for outcomes of benefits and harms -->

\
\
<!--# The number of PRO outcome data at baseline and atsubsequent time points should be made transparent -->

Some general comments are;

-   The participant flow is explained in text, but this would be so much easier to understand with a flow chart. Especially trying to understand who was eligible for which outcomes at which follow up. I assume they didnt ask graft failure patients to be included at the post-failure timepoints for example.

-   There is clearly a concerted effort to retrieve patients (in some form) at 5 years, compared to the 4 year followup (Table 1 [@pinczewski2002]).

-   There is a risk of survivor bias in the PROMs assessment at 10 years with \~25% of cases failed by then. What would happen if a comparison were made based on ITT?

<!--# The number of PRO outcome data at baseline and at subsequent time points should be made transparent -->

The followup of patients at the final timepoint is noted in the follow-up section. This could be communicated more effectively with a comprehensive flowchart incorporating all published timepoints.

## CONSORT \[13b\] Losses and Exclusions per Group

<!--# For each group, losses and exclusions after randomisation, together with reasons -->

This is done reasonably well, but see comments above with respect to differentiating eligibility of different outcome measures.

## CONSORT \[14a\] Recruitment Period

<!--# Dates defining the periods of recruitment and follow-up -->

PT Group - Jan-1993 to Apr-1994

HT Group - Oct-93 to Nov-1994

The authors state "senior author...after Apr-1994..used the HT graft exclusively". Does this comparison not include the learning curve for HT? Why not start recruitment of HT group after Apr-1994?

The specific followup dates are not included in any of the trial papers - this is particularly important for interpreting the PROMs.

## CONSORT \[14b\] Trial Termination

<!--# Why the trial ended or was stopped -->

No description of trial termination in the methods. However, there is a section in [@pinczewski2002] talking about abandoning the trial due to recruitment failure (see *Randomisation*).

## CONSORT \[15\] Baseline Data

<!--# A table showing baseline demographic and clinical characteristics for each group -->

There is no table of demographics in this paper, but there is in [@roe2005].

<!--# Including baseline PRO data when collected -->

No baseline PRO data was collected for this study.

Now let's do a few checks on the demographics, starting with a quick rehash of the key data reported in the paper.

| Parameter       | PT  | HT  |
|-----------------|-----|-----|
| Females (Count) | 42  | 43  |
| Age (Median)    | 25  | 24  |
| Age (Min)       | 13  | 13  |
| Age (Max)       | 42  | 52  |

### Age

Well, first of all - I'm not sure this would pass HREC in the present day. ACL reconstruction in skeletally immature individuals within a trial setting is a different set of ethical considerations to adults and I'm not sure a mixed sample like this would pass muster in the present environment (assuming there was genuine uncertainty in the best surgical approach). Considering the narrowness of the inclusion criteria, adding in immature patients into the sample is an interesting choice. The inclusion of paediatric patients also raises issues for the validity of the PROMs included in the outcomes (see CONSORT 6).

The other question that comes to mind is what are the chances that two groups separated by a cutoff in time, would have the exact same average age? That is difficult to answer without knowing more about the i) the underlying age distribution of the clinic population and ii) the selected samples distributions. Seeing that a median and range is reported, I assume that the data was skewed (to lower ages). The other thing I notice is that the recruitment period is slightly different between groups, so it is definitely plausible that two similarly aged groups could be derived from the practice flow.

Let's see what happens when we try to simulate a normal distribution of age in both groups. I'll use the *rsprite2* package (v`{r} utils::packageVersion("rsprite2")`) [@rsprite2] to generate plausible distributions.

The first problem is that the median (50th percentile) for the either group is nowhere near the midpoint of the range `{r} 13 + ((42-13)/2)` reported. So what to use as the estimated mean? Let's first try with [@wan2014] equation 3 and for the SD we'll use equation 9 from the same paper.

```{r}

AgeMeanPT <- (13 + (2*25) + 42)/4

```

The SD is a bit more complicated so I'll need a function to implement the equation.\

```{r}
estimate_sd_from_range <- function(min_val, max_val, n) {
  # min_val: minimum value (a)
  # max_val: maximum value (b)
  # n: sample size
  
  # Calculate the range
  range_val <- max_val - min_val
  
  # Calculate the denominator using the inverse normal CDF
  denominator <- 2 * qnorm((n - 0.375) / (n + 0.25))
  
  # Estimate the standard deviation
  sd_estimate <- range_val / denominator
  
  return(sd_estimate)
}

# Example usage
AgeSDPT <- estimate_sd_from_range(min_val = 13, max_val = 42, n = 90)
```

```{epoxy}

So now for the PT group we have an estimated mean of {round(AgeMeanPT,3)} and SD of {round(AgeSDPT,3)}.

```

Plugged into the *rsprite2* functions gives an error that *the mean is not consistent with number of observations (fails GRIM test)*.

Taking a step back and rerunning the grim test function produces a slightly adjusted mean instead.

```{r, AgeGrimMean}

rsprite2::GRIM_test(
  mean = AgeMeanPT,
  n_obs = 90,
  m_prec = 3,
  return_values = TRUE
)

```

The standard deviation needed a bit of tweaking to pass the GRIMMER test. The value that passed was 5.855.

```{r, AgeGrimSD}
rsprite2::GRIMMER_test(
  mean = 26.244,
  sd = 5.855,
  n_obs = 90,
  m_prec = 3,
  sd_prec = 3,
  n_items = 1,
  min_val = 13,
  max_val = 42
)
```

PLugging the modified mean and SD back in;

```{r, RSprite Age}


AgeDistPT_Param <- rsprite2::set_parameters(
  mean = 26.244, 
  sd = 5.855, 
  n_obs = 90, 
  min_val = 13,
  max_val = 42
  )

AgeDistPT <- rsprite2::find_possible_distributions(
  parameters = AgeDistPT_Param, 
  n_distributions = 10, 
  return_tibble = TRUE
  )

rsprite2::plot_distributions(
  distributions = AgeDistPT,
  plot_type = "histogram"
  )

```

So I still have questions about the age distribution as it doesnt fit the estimated parameters (no values near 40 for example, when the reported maximum is 42). I suspect the HT group will be even more deviant from the estimates as the range is wider (max out to 52). At this stage, the age distributions remain a mystery.

### Sex

I also wanted to know if the proportion of females is generalisable, so I established the female proportion in both study groups combined (they are also the same between groups), compared with the New Zealand ACL Registry data in the latest report [@aclregistry2024].

```{r, SexCheck}
SexCheck <- list(
  Group = prop.test(42 + 43, 180, 0.95),
  NZRegistry = prop.test(8816,8816+11581,conf.level = 0.95)
)
```

```{epoxy, GrimCheck}
A quick GRIM check of the female proportion returns [{scrutiny::grim(as.character(SexCheck$Group$estimate*100), n = 180, percent = TRUE)}] 
```

```{epoxy, SexCompare}

The proportion of females in the selected study {round(SexCheck$Group$estimate,2)} ({round(SexCheck$Group$conf.int[1],2)}, {round(SexCheck$Group$conf.int[2],2)}) is in line with the NZ ACL Registry {round(SexCheck$NZRegistry$estimate,2)} ({round(SexCheck$NZRegistry$conf.int[1],2)}, {round(SexCheck$NZRegistry$conf.int[2],2)})

```

## CONSORT \[16\] Numbers Analysed

<!--# For each group, number of participants (denominator) included in each analysis and whether the analysis was by original assigned groups -->

The numbers get tricky depending on which outcome category we are talking about in this paper. Broadly they can be broken down into whether the patient was;

-   Contactable by phone

-   Willing and able to undergo a followup x-ray

-   Available to return to clinic for assessment

As far as is interpretable, the analysis is by original assigned groups throughout.

What is of concern is the mixing of patient groups and eligibility criteria for analyses with respect to different outcomes. This has been outlined in the text of the paper and highlights varying criteria from one followup to the next (and the respective reporting) around objective and subjective outcomes for patients with ipsilateral or contralateral ligament/graft rupture. This makes tracing the numbers analysed from one paper in the series to the next extremely challenging.

## CONSORT \[17a1\] Outcomes and Estimation

<!--# For each primary and secondary outcome of benefits and harms, results for each group, and the estimated effect size and its precision (such as 95% confidence interval) -->

<!--# For multidimensional PRO results from each domain and time point -->

Let's try out some checks -see how far we get. Let's use *statcheck* package first, see if we can get a bite.

```{r, StatCheck, execute = FALSE}
statcheck::checkPDF("~/Pinczewski et al 2007.pdf")
```

This is not surprising - the results are not formatted in APA style (not unusual for the field).

Overall, the paper reports benefits and harms for each group, but *doesnt* report the between-group effect size or its precision (confidence intervals). The PROMs are a bit trickier in terms of reporting, the IKDC and Lysholm scores are not really multidimensional, in the sense that many PROMs in this field capture responses on different *dimensions* or themes, and instead just report a total score of some sort.

There are a couple of other problems with the outcomes and estimation in this paper. The first is that none of the between-group comparisons are adjusted for potential confounders, which does not necessarily address confounder bias in this context, but does have an impact on test efficiency. I can see the reasoning here - if there are no differences in covariates between groups, then they don't meet the definition of a confounder. However, adjusted comparisons can be more statistically powerful than unadjusted. The second problem is the impact of contralateral limb ACL rupture on estimates of a number of outcomes reported. In this regard, the contralateral rupture is a *competing risk* (an event that prevents the event of interest from happening; e.g. mortality [@schuster2020]) with respect to the graft survival estimates. If a patient were to subsequently experience such a rupture event, there is a much diminished exposure to ipsilateral rerupture during the first 6-9 months of recovery, as they are laid up and gradually return to activities that expose the reconstructed ligament to re-injury. This can lead to bias (bias upward) of the hazard estimate when using Kaplan-Meier estimation for survival [@kim2007].

## CONSORT \[17a2\] Outcomes Omitted

<!--# For outcomes omitted from the trial report (benefits and harms), provide rationale for not reporting and indicate where the data on omitted outcomes can be accessed -->

This is a bit of a mystery. Without access to a protocol prepared prior to the first follow up report, its impossible to know what has been omitted.

## CONSORT \[17b\] Binary Outcomes

<!--# For binary outcomes, presentation of both absolute and relative effect sizes is recommended -->

Relative effect sizes (with confidence intervals) are not reported in this trial.

## CONSORT \[17c\] Zero Events

<!--# Report zero events if no harms were observed -->

This is also difficult to discern as a comprehensive list of harms under investigation was not prepared a-priori. It is tough to distinguish harms that have been dropped from each report versus zero events.

## CONSORT \[18\] Ancillary Analyses

<!--# Results of any other analyses performed, including subgroup analyses and adjusted analyses, distinguishing pre-specified from exploratory -->

No subgroup or adjusted analyses performed. Exploratory versus pre-specified are not distinguished in the text.

## CONSORT \[19\] Harms

<!--# All important harms or unintended effects in each group (for specific guidance see CONSORT for harms) -->

Harms are reported in the text, but the paper suffers from a lack of structure to how harms were defined, recorded and analysed.

# Discussion

## CONSORT \[20\] Limitations

<!--# Trial limitations, addressing sources of potential bias related to the approach to collecting or reporting data on harms, imprecision, and, if relevant, multiplicity or selection of analyses-->

<!--# P20/21: PRO–specific limitations and implications for generalizability and clinical practice -->

What did the authors cover in their discussion?

-   Lack of randomisation

-   Lack of blinding

    -   (blinding was not possible): I take some issue with this, this could have been addressed with some more effort during in-clinic visits (e.g. a knee sleeve) and ii) separation of roles within the study team.

-   Inclusion of HT learning curve in the analysis

What was not covered was the potential sources of bias related to the collection and reporting of all outcomes (particularly harms) and the issue of multiplicity of analyses. Limitations specific to PROMs and implications for generalisability and implementation to clinical practice were also not covered.

## CONSORT \[21\] Generalisability

<!--# Generalizability (external validity, applicability) of the trial findings -->

Some comments could be made regarding the applicability of the findings to general practice. I have referred to some issues with inclusion and exclusion criteria above, and the numbers of total reviewed cases per year versus the group size indicate that the study sample was quite narrow.

The question that arises from the present review is the lack of equipoise in the intervention groups and whether other centres with lower volume surgeons and different perioperative care expectations may have achieved different responses. Balancing between the short-term gains of faster return to function in the new treatment option versus the potential for elevated risk of graft rupture with respect to patient preferences is an important component of achieving sufficient equipoise to successfully complete a trial in this context. Further, when it comes to reporting harms from an emerging surgical technique (reconstruction with hamstring graft), it would seem responsible to report all observed harms associated with the procedure by detailed review of *all* cases performed, rather than a small sub-sample as included in this trial. Importantly, whether this trial still fits within a contemporary practice in the same way it might have at the turn of the century remains a question.

## CONSORT \[22\] Interpretation

<!--# Interpretation consistent with results, balancing benefits and harms, and considering other relevant evidence -->

<!--# PRO data should be interpreted in relation to clinical outcomes including survival data, where relevant -->

*Was the original interpretation balanced?*

-   Conflating selective recruitment for "control of variables"

-   Overinflating the importance of non-significant findings for underpowered comparisons

-   Describing trends in OA incidence, with no reference to population norms

-   Relying on flawed regressions (Table 2 fallacy)

-   Subsequent changes in surgical technique

-   Follow up study results(?)

*How should we interpret in the present context?*

-   Previous authors have assessed the risk of bias in the study to be *questionable.*

-   The present review revealed

    -   Underpowered analyses

    -   Risk of Type 1 error due to multiplicity of tests - at least a few of the reported significant p-values are likely to be due to chance

    -   Unadjusted comparisons with simplistic data models

    -   Using binary comparisons in time-to-event outcomes

    -   Ignoring time-varying covariates (e.g. age)

    -   Ignoring competing risks in time-to-event outcomes

Does it stack up in terms of how its been cited?\
\
Example 1: [@kamatsuki2024]

> *Pinczewski et al \[45\] reported a side-to-side difference in AP laxity of \>2 mm at 2 years after surgery to be associated with an increased risk for graft rupture in a 10-year follow-up study after ACL reconstructions.*

Well let's unpack that a little bit. This finding was reported from a poorly described linear regression, with a risk of Table 2 fallacy. For those unfamiliar, this fallacy is where effect estimates (usually presented in a regression summary making up Table 2 of a clinical research paper) are misinterpreted to be of the same type (direct versus indirect) when relaying coefficients [@westreich2013]. Full disclosure here, this is a mistake we have all made at some point in this domain, but it is relevant here when assessing the appropriateness of key papers.

Example 2: [@khan2024]

> *the available literature suggests a higher contralateral tear rate with BPTB autografts relative to HST autografts \[13-**15**\].*

This finding is referenced from a binary comparison between graft groups that is not well described in the text of the paper. It is unclear what denominator has been used in the calculation (N = 90?). The issues with using binary classification in time-to-event outcomes, has been discussed elsewhere [@salika2022]. Overall, ignoring censoring and in this domain, the competing risk of injury (see CONSORT 17a) to either limb with respect to reinjury risk is fraught and needs to be re-examined.

Example 3: [@widhalm2024]

> *Since the objective result measurements of ROM and stability do not necessarily correspond to the subjective functionality of a knee joint after cruciate ligament reconstruction \[40\], the subjective outcome was evaluated by using four standardized questionnaires frequently used in studies: the International Knee Documentation Committee Subjective Knee Form (IKDC) \[19,40,**41**\],*

This example is frustratingly common in the literature - speaking from experience, it is incredibly easy to identify a paper that shares the name of the scale you think you want to use and it turns out to be i) a different version of the same scale created by the original developers, ii) an iteration or refinement by a different group or iii) not the same scale at all, just mislabelled or shares elements of the name. Unfortunately for this citing paper, the IKDC they are referring to is the IKDC2000, which is not the same questionnaire used in the article of interest (although the subjective questions are similar).

# References

Literature and package usage
